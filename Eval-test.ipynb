{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6d7f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ontology_generation.Evaluation import Evaluation\n",
    "from ontology_generation.OntologyGen import OntologyGen\n",
    "from ontology_generation.OntologyEncap import OntologyEncap\n",
    "import re\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "from rdflib import Namespace, Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2466d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontogen = OntologyGen(model_name=\"gpt-4-1106-preview\", deployment_name=\"gpt_chat_test_preview\")\n",
    "topic_name = \"natural language processing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee684cf",
   "metadata": {},
   "source": [
    "#### CSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa5674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "file_path = \"data/CSO.3.3.ttl\"\n",
    "parent_topic_uri = \"https://cso.kmi.open.ac.uk/topics/natural_language_processing\"\n",
    "deduplicated_topics = Evaluation.extract_concepts_and_deduplicate(file_path, parent_topic_uri)\n",
    "cso_concepts = Evaluation.process_concepts(deduplicated_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0376b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of concepts in CSO before deduplication:  55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['dependency_parser',\n",
       " 'part-of-speech_tagging',\n",
       " 'pseudo_relevance_feedback',\n",
       " 'relevance_models',\n",
       " 'part_of_speech_tagging',\n",
       " 'sequence_labeling',\n",
       " 'syntactic_analysis',\n",
       " 'syntactic_features',\n",
       " 'abstracting_and_indexing',\n",
       " 'statistical_language_models',\n",
       " 'syntactic_structure',\n",
       " 'information_extraction',\n",
       " 'maximum_entropy_models',\n",
       " 'semantic_similarity_measures',\n",
       " 'syntactic_parsing',\n",
       " 'parse_trees',\n",
       " 'spoken_language_processing',\n",
       " 'cross-language_information_retrieval',\n",
       " 'topic_model',\n",
       " 'parsing_algorithm',\n",
       " 'computing_with_words',\n",
       " 'lexical_semantics',\n",
       " 'sentiment_analysis',\n",
       " 'named_entity',\n",
       " 'spoken_dialogue_system',\n",
       " 'maximum_entropy_model',\n",
       " 'named_entities',\n",
       " 'natural_language_generation',\n",
       " 'syntactic_information',\n",
       " 'spoken_dialogue_systems',\n",
       " 'treebanks',\n",
       " 'machine_translation',\n",
       " 'computing_with_word_%28cww%29',\n",
       " 'information_retrieval_technology',\n",
       " 'n-gram_models',\n",
       " 'lexical_database',\n",
       " 'synsets',\n",
       " 'natural_language_text',\n",
       " 'statistical_language_modeling',\n",
       " 'lexical_resources',\n",
       " 'parsing',\n",
       " 'machine_translations',\n",
       " 'text_processing',\n",
       " 'dependency_parsing',\n",
       " 'question_answering_system',\n",
       " 'word_embeddings',\n",
       " 'question_answering_systems',\n",
       " 'word_segmentation',\n",
       " 'computational_grammars',\n",
       " 'speech_transmission',\n",
       " 'word_embedding',\n",
       " 'n-gram_language_models',\n",
       " 'natural_language_understanding',\n",
       " 'cross_language_information_retrieval',\n",
       " 'semantic_similarity']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of concepts in CSO before deduplication: \", len(cso_concepts))\n",
    "cso_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91feee83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['dependency_parser',\n",
       " 'part-of-speech_tagging',\n",
       " 'pseudo_relevance_feedback',\n",
       " 'relevance_models',\n",
       " 'sequence_labeling',\n",
       " 'syntactic_analysis',\n",
       " 'syntactic_features',\n",
       " 'abstracting_and_indexing',\n",
       " 'statistical_language_models',\n",
       " 'syntactic_structure',\n",
       " 'information_extraction',\n",
       " 'maximum_entropy_models',\n",
       " 'semantic_similarity_measures',\n",
       " 'syntactic_parsing',\n",
       " 'parse_trees',\n",
       " 'spoken_language_processing',\n",
       " 'cross-language_information_retrieval',\n",
       " 'topic_model',\n",
       " 'parsing_algorithm',\n",
       " 'computing_with_words',\n",
       " 'lexical_semantics',\n",
       " 'sentiment_analysis',\n",
       " 'named_entity',\n",
       " 'spoken_dialogue_system',\n",
       " 'natural_language_generation',\n",
       " 'syntactic_information',\n",
       " 'treebanks',\n",
       " 'machine_translation',\n",
       " 'computing_with_word_%28cww%29',\n",
       " 'information_retrieval_technology',\n",
       " 'n-gram_models',\n",
       " 'lexical_database',\n",
       " 'synsets',\n",
       " 'natural_language_text',\n",
       " 'lexical_resources',\n",
       " 'parsing',\n",
       " 'text_processing',\n",
       " 'question_answering_system',\n",
       " 'word_embeddings',\n",
       " 'word_segmentation',\n",
       " 'computational_grammars',\n",
       " 'speech_transmission',\n",
       " 'n-gram_language_models',\n",
       " 'natural_language_understanding',\n",
       " 'semantic_similarity']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Function to normalize topics\n",
    "def normalize_topic(topic):\n",
    "    # Convert to lowercase and replace hyphens with underscores\n",
    "    topic = topic.lower().replace(\"-\", \"_\")\n",
    "    # Remove trailing 's' for plurals\n",
    "    topic = re.sub(r's$', '', topic)\n",
    "    # Remove parentheses and their contents\n",
    "    topic = re.sub(r'\\([^)]*\\)', '', topic)\n",
    "    # Remove any remaining special characters and extra whitespace\n",
    "    topic = re.sub(r'[^a-z0-9_]', '', topic)\n",
    "    return topic\n",
    "\n",
    "# Function to check if two topics are similar based on a threshold\n",
    "def are_similar(a, b, threshold=0.85):\n",
    "    return SequenceMatcher(None, a, b).ratio() > threshold\n",
    "\n",
    "# Set for normalized topics to track seen ones\n",
    "seen = set()\n",
    "# List to store unique topics\n",
    "unique_topics = []\n",
    "\n",
    "# First pass: Remove exact duplicates using normalization\n",
    "for topic in cso_concepts:\n",
    "    normalized = normalize_topic(topic)\n",
    "    if normalized not in seen:\n",
    "        seen.add(normalized)\n",
    "        unique_topics.append(topic)\n",
    "\n",
    "# Second pass: Check for similar topics using SequenceMatcher\n",
    "final_topics = []\n",
    "for topic in unique_topics:\n",
    "    if not any(are_similar(normalize_topic(topic), normalize_topic(existing)) for existing in final_topics):\n",
    "        final_topics.append(topic)\n",
    "\n",
    "# Print the number of unique topics and the topics themselves\n",
    "print(len(final_topics))\n",
    "final_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b32fbee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# role = \"You are an ontology engineer\"\n",
    "# prompt = f'''You are a model tasked with deleting duplicate topics from a list for ontology creation for the {topic_name} domain. \n",
    "# The list: ''' + ', '.join(unique_topics) + '''\n",
    "# Return the response only in the dictionary format. Do not add new topics. Ensure proper use of quotations:\n",
    "# {\n",
    "# 'topic1',\n",
    "# 'topic2\n",
    "# }\n",
    "# '''\n",
    "# cso_list = ontogen.prompt_extract(role, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6527be66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of concepts in CSO:  42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dependency_parser': 'dependency_parsing',\n",
       " 'part-of-speech_tagging': 'part-of-speech_tagging',\n",
       " 'pseudo_relevance_feedback': 'pseudo_relevance_feedback',\n",
       " 'relevance_models': 'relevance_models',\n",
       " 'sequence_labeling': 'sequence_labeling',\n",
       " 'syntactic_analysis': 'syntactic_analysis',\n",
       " 'syntactic_features': 'syntactic_features',\n",
       " 'abstracting_and_indexing': 'abstracting_and_indexing',\n",
       " 'statistical_language_models': 'statistical_language_modeling',\n",
       " 'syntactic_structure': 'syntactic_structure',\n",
       " 'information_extraction': 'information_extraction',\n",
       " 'maximum_entropy_models': 'maximum_entropy_models',\n",
       " 'semantic_similarity_measures': 'semantic_similarity',\n",
       " 'syntactic_parsing': 'syntactic_parsing',\n",
       " 'parse_trees': 'parse_trees',\n",
       " 'spoken_language_processing': 'spoken_language_processing',\n",
       " 'cross-language_information_retrieval': 'cross-language_information_retrieval',\n",
       " 'topic_model': 'topic_model',\n",
       " 'parsing_algorithm': 'parsing_algorithm',\n",
       " 'computing_with_words': 'computing_with_word_%28cww%29',\n",
       " 'lexical_semantics': 'lexical_semantics',\n",
       " 'sentiment_analysis': 'sentiment_analysis',\n",
       " 'named_entity': 'named_entities',\n",
       " 'spoken_dialogue_system': 'spoken_dialogue_system',\n",
       " 'natural_language_generation': 'natural_language_generation',\n",
       " 'syntactic_information': 'syntactic_information',\n",
       " 'treebanks': 'treebanks',\n",
       " 'machine_translation': 'machine_translation',\n",
       " 'information_retrieval_technology': 'information_retrieval_technology',\n",
       " 'n-gram_models': 'n-gram_language_models',\n",
       " 'lexical_database': 'lexical_database',\n",
       " 'synsets': 'synsets',\n",
       " 'natural_language_text': 'natural_language_text',\n",
       " 'lexical_resources': 'lexical_resources',\n",
       " 'parsing': 'parsing',\n",
       " 'text_processing': 'text_processing',\n",
       " 'question_answering_system': 'question_answering_system',\n",
       " 'word_embeddings': 'word_embeddings',\n",
       " 'word_segmentation': 'word_segmentation',\n",
       " 'computational_grammars': 'computational_grammars',\n",
       " 'speech_transmission': 'speech_transmission',\n",
       " 'natural_language_understanding': 'natural_language_understanding'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(\"Number of concepts in CSO: \", len(cso_list))\n",
    "# cso_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641daceb",
   "metadata": {},
   "source": [
    "#### AutOnto with OA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a0a2b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_uri = \"http://fraunhofer.de/example/Natural_Language_Processing\"\n",
    "graph = Graph()\n",
    "graph.parse(\"output/taxonomy_withOA.ttl\", format=\"ttl\")  # Load your RDF data\n",
    "\n",
    "descendants_withOA = Evaluation.get_descendants(concept_uri, graph)\n",
    "concepts_onto_withOA = Evaluation.clean_concept_names(descendants_withOA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4efb85",
   "metadata": {},
   "source": [
    "#### AutOnto w/o OA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd8a2500",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_uri = \"http://fraunhofer.de/example/Natural_language_processing\"\n",
    "file_path = \"output/taxonomy_withoutOA.ttl\"\n",
    "\n",
    "graph = Graph()\n",
    "graph.parse(\"output/taxonomy_withoutOA.ttl\", format=\"ttl\")  # Load your RDF data\n",
    "\n",
    "descendants_withoutOA = Evaluation.get_descendants(concept_uri, graph)\n",
    "concepts_onto__withoutOA = Evaluation.clean_concept_names(descendants_withoutOA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f79cf0",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9031e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of concepts in CSO:  45\n",
      "Number of concepts in OntoNLP with OA:  75\n",
      "Number of concepts in OntoNLP with OA:  56\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of concepts in CSO: \", len(final_topics))\n",
    "print(\"Number of concepts in OntoNLP with OA: \", len(concepts_onto_withOA))\n",
    "print(\"Number of concepts in OntoNLP with OA: \", len(concepts_onto__withoutOA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94ff014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalinst = Evaluation()\n",
    "\n",
    "cso_list_processed = evalinst.preprocess_list(final_topics)\n",
    "concepts_onto_withOA_processed = evalinst.preprocess_list(concepts_onto_withOA)\n",
    "concepts_onto_withoutOA_processed = evalinst.preprocess_list(concepts_onto__withoutOA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24e4e56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrut\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained SentenceTransformer model\n",
    "whaleloops_model = SentenceTransformer(\"whaleloops/phrase-bert\")\n",
    "\n",
    "# Calculate metrics for preprocessed_list1\n",
    "phrase_embeddings1 = whaleloops_model.encode(cso_list_processed)\n",
    "reference_embedding = whaleloops_model.encode('natural-language-processing')\n",
    "metrics1 = Evaluation.calculate_metrics(phrase_embeddings1, reference_embedding)\n",
    "\n",
    "# Calculate metrics for preprocessed_list2\n",
    "phrase_embeddings2 = whaleloops_model.encode(concepts_onto_withOA_processed)\n",
    "metrics2 = Evaluation.calculate_metrics(phrase_embeddings2, reference_embedding)\n",
    "\n",
    "# Calculate metrics for preprocessed_list2\n",
    "phrase_embeddings3 = whaleloops_model.encode(concepts_onto_withoutOA_processed)\n",
    "metrics3 = Evaluation.calculate_metrics(phrase_embeddings3, reference_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b53c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dictionaries to store the metrics\n",
    "data = [\n",
    "    {\n",
    "        \"List\": \"CSO\",\n",
    "        \"Number of Terms\": len(cso_list_processed),\n",
    "        **metrics1\n",
    "    },\n",
    "    {\n",
    "        \"List\": \"AutOnto with OA concepts\",\n",
    "        \"Number of Terms\": len(concepts_onto_withOA_processed),\n",
    "        **metrics2\n",
    "    },\n",
    "        {\n",
    "        \"List\": \"AutOnto without OA concepts\",\n",
    "        \"Number of Terms\": len(concepts_onto_withoutOA_processed),\n",
    "        **metrics3\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create the DataFrame from the list of dictionaries\n",
    "comparison = pd.DataFrame(data)\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "comparison.to_csv(\"output/metrics_comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29de65e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
